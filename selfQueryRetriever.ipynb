{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "import pprint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_KEY')\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectordb = Chroma(persist_directory=\"./jonhWick_db\", embedding_function=embeddings, collection_name=\"doc_jonhWick\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----  Start ids --- \n",
      "\n",
      "['04862bf7-2f07-4273-bd00-5fefe76256ce']\n",
      " ----  End ids --- \n",
      "\n",
      " ----  Start embeddings --- \n",
      "\n",
      "None\n",
      " ----  End embeddings --- \n",
      "\n",
      " ----  Start metadatas --- \n",
      "\n",
      "[{'Author': 'Coventry',\n",
      "  'Movie_Title': 'John Wick 1',\n",
      "  'Rating': 5,\n",
      "  'Review_Date': '5 May 2023',\n",
      "  'Review_Title': \" You don't mess with another person's dog. It's as simple \"\n",
      "                  'as that!\\n',\n",
      "  'Review_Url': '/review/rw9033669/?ref_=tt_urv',\n",
      "  'row': 2,\n",
      "  'source': 'data/john_wick_1.csv'}]\n",
      " ----  End metadatas --- \n",
      "\n",
      " ----  Start documents --- \n",
      "\n",
      "[': 2\\n'\n",
      " \"Review: With the fourth installment scoring immensely at the cinemas as I'm \"\n",
      " 'submitting this review, and after three previous films that are apparently '\n",
      " 'loved by everyone else in the world, I thought perhaps it would be time for '\n",
      " 'me check out \"John Wick\".']\n",
      " ----  End documents --- \n",
      "\n",
      " ----  Start uris --- \n",
      "\n",
      "None\n",
      " ----  End uris --- \n",
      "\n",
      " ----  Start data --- \n",
      "\n",
      "None\n",
      " ----  End data --- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_example = vectordb.get(ids=vectordb.get()['ids'][0])\n",
    "for key in doc_example:\n",
    "\n",
    "    print(f\" ----  Start {key} --- \\n\" )\n",
    "    pprint.pprint(doc_example[key])\n",
    "    print(f\" ----  End {key} --- \\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see, we have 9 fields inside to the metadata "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to create a self Query Retriever. Este tipo de retriever es muy util cuando la fuente de datos de nuestra vectore store tiene metadatos claves para busqueda optima de la respuesta.\n",
    "\n",
    "Veamos el siguiente ejemplo. Imaginemos que tenemos almacenado en nuestra base de datos vectorial una gran cantidad de experiencias y ofertas de ocio (Ex: clases de surf, tirolina, ruta gastronómica, etc ). La descripción de la experiencia es lo que hemos codificado, usando nuestro modelo de embbedding. Además cada oferta tiene 3 valores claves o metadatos: Fecha, precio y lugar.\n",
    "\n",
    "Imaginemos que un usuario busca una experiencia de este estilo: Una experiencia en la naturaleza, que sea para toda la familia y segura. Además el precio debe de ser inferior a 50$  y el lugar es California. \n",
    "\n",
    "Algo esta claro aquí, \"NO QUEREMOS QUE NOS DEVUELVA ACTIVIDAD/EXPERIENCIAS QUE NO CUMPLAN EL PRECIO NI EL LUGAR QUE EL USUARIO PIDE\". Por ello no tiene sentido calcular similitudes con chunks/experiencias que no cumplan con el filtro de los metadatos. \n",
    "\n",
    "Este caso es ideal para aplicar \"self Query Retriever\". \n",
    "\n",
    "Volviendo a nuestro ejemplo anterior, lo que nos permite este tipo de retriever es realizar un primer filtro a través de los metadas, y después realizar el calculo de similitud entre los chunks que cumplan los requisitos de los metadatos y el input del usuario.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿La pregunta que nos tenemos que hacer es la siguiente: ¿Como sabe el agente usando en el SQR, cuales son los filtros de la vectore store y que significa cada uno?\n",
    "\n",
    "Para eso necesitamos darle un contexto a este agente, donde le mostraremos cuales son los metadatos y la descripción de cada uno de ellos. Al proporcionarle este conocimiento, el agente podrá saber cuando y como hacer el filtro al hacer las consultas. Además le tendremos que dar una descripción de la info que va a encontrarse en la vectore store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "\n",
    "\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"Movie_Title\",\n",
    "        description=\"The title of the movie\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Review_Date\",\n",
    "        description=\"The date of the review\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Review_Title\",\n",
    "        description=\"The title of the review\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Review_Url\",\n",
    "        description=\"The URL of the review\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Author\",\n",
    "        description=\"The author of the review\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Rating\",\n",
    "        description=\"A 1 to 10 rating for the movie\",\n",
    "        type=\"integer\",\n",
    "    )\n",
    "]\n",
    "\n",
    "document_content_desription = \"A review of the Jonh Wick movie.\"\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "chat_model = ChatOpenAI()\n",
    "\n",
    "self_query_retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    vectorstore =vectordb,\n",
    "    document_contents = document_content_desription,\n",
    "    metadata_field_info =metadata_field_info,\n",
    "    verbose = True,\n",
    "    structured_query_translator = ChromaTranslator()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are going to do a Naive RAG.\n",
    "\n",
    "## Remember:\n",
    "\n",
    "- R -> Retrieval\n",
    "- A -> Augmented\n",
    "- G -> Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelfQueryRetriever(vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001EAC42E1750>, query_constructor=RunnableBinding(bound=FewShotPromptTemplate(input_variables=['query'], examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}], example_prompt=PromptTemplate(input_variables=['data_source', 'i', 'structured_request', 'user_query'], template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n'), suffix='<< Example 3. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"A review of the Jonh Wick movie.\",\\n    \"attributes\": {{\\n    \"Movie_Title\": {{\\n        \"description\": \"The title of the movie\",\\n        \"type\": \"string\"\\n    }},\\n    \"Review_Date\": {{\\n        \"description\": \"The date of the review\",\\n        \"type\": \"string\"\\n    }},\\n    \"Review_Title\": {{\\n        \"description\": \"The title of the review\",\\n        \"type\": \"string\"\\n    }},\\n    \"Review_Url\": {{\\n        \"description\": \"The URL of the review\",\\n        \"type\": \"string\"\\n    }},\\n    \"Author\": {{\\n        \"description\": \"The author of the review\",\\n        \"type\": \"string\"\\n    }},\\n    \"Rating\": {{\\n        \"description\": \"A 1 to 10 rating for the movie\",\\n        \"type\": \"integer\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | ne | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001EAD7BFBE80>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001EAD7C098A0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), config={'run_name': 'query_constructor'}), structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x000001EAC442C400>, verbose=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have already created the retriever object\n",
    "self_query_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "TEMPLATE = \"\"\"\\\n",
    "You are happy assistant. Use the context provided below to answer the question.\n",
    "\n",
    "If you do not know the answer, or are unsure, say you don't know.\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, we are going to create a Rag Parent doc Retrieval. For that, we are going to use LCEL (LangChain Expression Language)\n",
    "If you want to learn more about LCEL, check this good tutorial: https://www.youtube.com/watch?v=O0dUOtOIrfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, people generally liked John Wick.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "setup_and_retrieval = RunnableParallel({\"question\": RunnablePassthrough(), \"context\": self_query_retriever })\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "selfq_retrieval_chain = setup_and_retrieval | rag_prompt | chat_model | output_parser\n",
    "\n",
    "\n",
    "selfq_retrieval_chain.invoke( \"Did people generally like John Wick?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The reviews with a score greater than 7 are:\\n1. Review by subxerogravity for the movie \"John Wick 2\" with a rating of 9.\\n2. Review by danielmanson for the movie \"John Wick 2\" with a rating of 8.\\n3. Review by ThomasDrufke for the movie \"John Wick 2\" with a rating of 8.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selfq_retrieval_chain.invoke(\"What are the reviews with a score greater than 7?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Author': 'subxerogravity', 'Movie_Title': 'John Wick 2', 'Rating': 9, 'Review_Date': '10 February 2017', 'Review_Title': \" Man! I didn't think Chapter 2 could out do the original, but man! This was Fantastic!\\n\", 'Review_Url': '/review/rw3637449/?ref_=tt_urv', 'row': 24, 'source': 'data/john_wick_2.csv'}\n",
      "{'Author': 'danielmanson', 'Movie_Title': 'John Wick 2', 'Rating': 8, 'Review_Date': '28 November 2020', 'Review_Title': \" It's just a great action film\\n\", 'Review_Url': '/review/rw6316364/?ref_=tt_urv', 'row': 1, 'source': 'data/john_wick_2.csv'}\n",
      "{'Author': 'ThomasDrufke', 'Movie_Title': 'John Wick 2', 'Rating': 8, 'Review_Date': '14 February 2017', 'Review_Title': ' Professional Courtesy\\n', 'Review_Url': '/review/rw3640053/?ref_=tt_urv', 'row': 2, 'source': 'data/john_wick_2.csv'}\n",
      "{'Author': 'Palidan400', 'Movie_Title': 'John Wick 1', 'Rating': 8, 'Review_Date': '25 October 2014', 'Review_Title': \" Yeah I'm Thinking He's Back\\n\", 'Review_Url': '/review/rw3111220/?ref_=tt_urv', 'row': 14, 'source': 'data/john_wick_1.csv'}\n"
     ]
    }
   ],
   "source": [
    "for docs in response:\n",
    "    print(docs.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rating value are always bigger than 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I want to look deeper into what is happening inside the self query retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:chain:query_constructor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What are the reviews with a score greater than 7 and say bad things about the movie?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:chain:query_constructor > 3:prompt:FewShotPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What are the reviews with a score greater than 7 and say bad things about the movie?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:chain:query_constructor > 3:prompt:FewShotPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:chain:query_constructor > 4:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Your goal is to structure the user's query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{\\n    \\\"query\\\": string \\\\ text string to compare to document contents\\n    \\\"filter\\\": string \\\\ logical condition statement for filtering documents\\n}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | ne | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \\\"NO_FILTER\\\" for the filter value.\\n\\n<< Example 1. >>\\nData Source:\\n```json\\n{\\n    \\\"content\\\": \\\"Lyrics of a song\\\",\\n    \\\"attributes\\\": {\\n        \\\"artist\\\": {\\n            \\\"type\\\": \\\"string\\\",\\n            \\\"description\\\": \\\"Name of the song artist\\\"\\n        },\\n        \\\"length\\\": {\\n            \\\"type\\\": \\\"integer\\\",\\n            \\\"description\\\": \\\"Length of the song in seconds\\\"\\n        },\\n        \\\"genre\\\": {\\n            \\\"type\\\": \\\"string\\\",\\n            \\\"description\\\": \\\"The song genre, one of \\\"pop\\\", \\\"rock\\\" or \\\"rap\\\"\\\"\\n        }\\n    }\\n}\\n```\\n\\nUser Query:\\nWhat are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"teenager love\\\",\\n    \\\"filter\\\": \\\"and(or(eq(\\\\\\\"artist\\\\\\\", \\\\\\\"Taylor Swift\\\\\\\"), eq(\\\\\\\"artist\\\\\\\", \\\\\\\"Katy Perry\\\\\\\")), lt(\\\\\\\"length\\\\\\\", 180), eq(\\\\\\\"genre\\\\\\\", \\\\\\\"pop\\\\\\\"))\\\"\\n}\\n```\\n\\n\\n<< Example 2. >>\\nData Source:\\n```json\\n{\\n    \\\"content\\\": \\\"Lyrics of a song\\\",\\n    \\\"attributes\\\": {\\n        \\\"artist\\\": {\\n            \\\"type\\\": \\\"string\\\",\\n            \\\"description\\\": \\\"Name of the song artist\\\"\\n        },\\n        \\\"length\\\": {\\n            \\\"type\\\": \\\"integer\\\",\\n            \\\"description\\\": \\\"Length of the song in seconds\\\"\\n        },\\n        \\\"genre\\\": {\\n            \\\"type\\\": \\\"string\\\",\\n            \\\"description\\\": \\\"The song genre, one of \\\"pop\\\", \\\"rock\\\" or \\\"rap\\\"\\\"\\n        }\\n    }\\n}\\n```\\n\\nUser Query:\\nWhat are songs that were not published on Spotify\\n\\nStructured Request:\\n```json\\n{\\n    \\\"query\\\": \\\"\\\",\\n    \\\"filter\\\": \\\"NO_FILTER\\\"\\n}\\n```\\n\\n\\n<< Example 3. >>\\nData Source:\\n```json\\n{\\n    \\\"content\\\": \\\"A review of the Jonh Wick movie.\\\",\\n    \\\"attributes\\\": {\\n    \\\"Movie_Title\\\": {\\n        \\\"description\\\": \\\"The title of the movie\\\",\\n        \\\"type\\\": \\\"string\\\"\\n    },\\n    \\\"Review_Date\\\": {\\n        \\\"description\\\": \\\"The date of the review\\\",\\n        \\\"type\\\": \\\"string\\\"\\n    },\\n    \\\"Review_Title\\\": {\\n        \\\"description\\\": \\\"The title of the review\\\",\\n        \\\"type\\\": \\\"string\\\"\\n    },\\n    \\\"Review_Url\\\": {\\n        \\\"description\\\": \\\"The URL of the review\\\",\\n        \\\"type\\\": \\\"string\\\"\\n    },\\n    \\\"Author\\\": {\\n        \\\"description\\\": \\\"The author of the review\\\",\\n        \\\"type\\\": \\\"string\\\"\\n    },\\n    \\\"Rating\\\": {\\n        \\\"description\\\": \\\"A 1 to 10 rating for the movie\\\",\\n        \\\"type\\\": \\\"integer\\\"\\n    }\\n}\\n}\\n```\\n\\nUser Query:\\nWhat are the reviews with a score greater than 7 and say bad things about the movie?\\n\\nStructured Request:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:chain:query_constructor > 4:llm:ChatOpenAI] [1.15s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"query\\\": \\\"bad things\\\",\\n    \\\"filter\\\": \\\"gt(\\\\\\\"Rating\\\\\\\", 7)\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```json\\n{\\n    \\\"query\\\": \\\"bad things\\\",\\n    \\\"filter\\\": \\\"gt(\\\\\\\"Rating\\\\\\\", 7)\\\"\\n}\\n```\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"name\": null,\n",
      "            \"id\": \"run-2f475df1-7266-4579-bb99-2118282445ab-0\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 26,\n",
      "      \"prompt_tokens\": 966,\n",
      "      \"total_tokens\": 992\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": \"fp_c2295e73ad\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:chain:query_constructor > 5:parser:StructuredQueryOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:chain:query_constructor > 5:parser:StructuredQueryOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:retriever:Retriever > 2:chain:query_constructor] [1.16s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\": 24\\nReview: John Wick: Chapter 3 - Parabellum is quite literally about consequences, dealing with the fallout of John's actions at the end of the previous film and sending him on an even bigger odyssey of violence that continues to explore this world of assassination and deliver beautifully clean action sequences.\", metadata={'Author': 'masonsaul', 'Movie_Title': 'John Wick 3', 'Rating': 10, 'Review_Date': '17 May 2019', 'Review_Title': ' Makes John Wick a superb trilogy\\n', 'Review_Url': '/review/rw4860603/?ref_=tt_urv', 'row': 24, 'source': 'data/john_wick_3.csv'}),\n",
       " Document(page_content=': 17\\nReview: There are actually quite a handful reasons why \"John Wick\" could have become a failure. The two directors have never made a film before and almost exclusively worked in the stunt department so far. The writer is not exactly experienced either. Lead actor Keanu Reeves usually scores more through boyish charm than through realistic portrayal of gritty badass characters. And the genre of crime action thrillers rarely delivers in terms of real significance. Still it became a very good film. The main reason for that is probably that it does not attempt to be anything of great cinematic value, does not try to teach groundbreaking stories on moral, loyalty or betrayal. Instead, Derek Kolstad\\'s script goes for a gutsy revenge thriller that is not even hurt by its occasional predictability.', metadata={'Author': 'Horst_In_Translation', 'Movie_Title': 'John Wick 1', 'Rating': 8, 'Review_Date': '27 February 2016', 'Review_Title': ' The man who kills the Boogeyman\\n', 'Review_Url': '/review/rw3422991/?ref_=tt_urv', 'row': 17, 'source': 'data/john_wick_1.csv'}),\n",
       " Document(page_content=\": 6\\nReview: In 2014, a Keanu Reeves revenge thriller John Wick became a surprise hit. I originally skipped out on the film as I felt that the trailers only showed an assassin story that I felt I've seen before. As far as I'm concerned, I made a big mistake. Before seeing the sequel, I felt it was important to watch the first one. I rented it on Amazon Prime and I was shock by what I saw; a dark, stylish, and fun action movie that is doing it's own thing. Though I've seen plenty stories about revenge (The Count of Monte Cristo and Moby Dick being the prime examples), I can't recall one over someone's pet being murdered.\", metadata={'Author': 'RforFilm', 'Movie_Title': 'John Wick 2', 'Rating': 8, 'Review_Date': '14 February 2017', 'Review_Title': \" John Wick: Chapter 2 continues it's faced paced, neo-noir story of our assassin\\n\", 'Review_Url': '/review/rw3639868/?ref_=tt_urv', 'row': 6, 'source': 'data/john_wick_2.csv'}),\n",
       " Document(page_content=': 3\\nReview: John wick has a very simple revenge story. It can be summarized as \"Keanu gets angry and shoots bad guys\" but what makes it special? Directed by Chad Stahelski who\\'s a stunt specialist boy does it show because the main selling point in the film are some real virtuoso action sequences, well made choreographies. Unlike today\\'s action movies, it doesn\\'t use quick-cuts or shaky cameras actually see what\\'s going on.', metadata={'Author': 'Kitsfi', 'Movie_Title': 'John Wick 1', 'Rating': 8, 'Review_Date': '28 September 2018', 'Review_Title': ' Keanu gets pissed and shoots people in the face for 101 minutes*\\n', 'Review_Url': '/review/rw4366368/?ref_=tt_urv', 'row': 3, 'source': 'data/john_wick_1.csv'})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.globals import set_verbose, set_debug\n",
    "\n",
    "set_debug(True)\n",
    "self_query_retriever.invoke(\"What are the reviews with a score greater than 7 and say bad things about the movie?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finaly, the query is : talk bad about the movie and the filter is \"Rating\" greater than 7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
